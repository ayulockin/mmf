includes:
- ../projects/unit/configs/vqa2_dataset_cfg.yaml
- ./defaults.yaml

other_configs:
  image_w: 384
  image_h: 384
  hidden_dim: 768

model_config:
  vilt:
    tasks: ${datasets}
    heads:
      vqa2:
        type: mlp
        num_labels: 3129

    image_encoder:
      type: vit
      params:
        random_init: False
        pretrained_model_name: google/vit-base-patch16-384
        image_size:
        - ${other_configs.image_w}
        - ${other_configs.image_h}
        hidden_dim: ${other_configs.hidden_dim}
        pretrained_model: vit_base_patch16_384
        mlp_dim: 3072

    image_embeddings:
      type: vilt_img_embedding
      params:
        image_size:
        - ${other_configs.image_w}
        - ${other_configs.image_h}
        hidden_dropout_prob: 0
        hidden_dim: ${other_configs.hidden_dim}
        hidden_size: ${other_configs.hidden_dim}
        patch_size: 16
        num_channels: 3
        random_init: False
        image_encoder: ${model_config.vilt.image_encoder}

    text_embeddings:
      type: vilt_text_embedding
      params:
        bert_model_name: bert-base-uncased
        hidden_dim: ${other_configs.hidden_dim}
        hidden_size: 768
